{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d436fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4591a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('heart failure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95339a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "259421c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('DEATH_EVENT',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b10e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['DEATH_EVENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d6a801b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  \n",
       "0        0     4  \n",
       "1        0     6  \n",
       "2        1     7  \n",
       "3        0     7  \n",
       "4        0     8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f3f21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: DEATH_EVENT, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44bdbc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEATH_EVENT\n",
       "0            1\n",
       "1            1\n",
       "2            1\n",
       "3            1\n",
       "4            1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d71b0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de271da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,random_state=40,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9660d7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df057d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>172000.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>228000.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>221000.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>337000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "136  65.0        1                        59         1                 60   \n",
       "111  55.0        0                        60         0                 35   \n",
       "168  65.0        0                       582         1                 40   \n",
       "271  51.0        0                       582         1                 40   \n",
       "175  60.0        1                        95         0                 60   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "136                    0   172000.0               0.9           137    0   \n",
       "111                    0   228000.0               1.2           135    1   \n",
       "168                    0   270000.0               1.0           138    0   \n",
       "271                    0   221000.0               0.9           134    0   \n",
       "175                    0   337000.0               1.0           138    1   \n",
       "\n",
       "     smoking  time  \n",
       "136        0   107  \n",
       "111        1    90  \n",
       "168        0   140  \n",
       "271        0   244  \n",
       "175        1   146  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a894e",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f12d6af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e14ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb2498ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ccfec3",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ea612cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41659ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "406d3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d2a72f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad54d198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85        59\n",
      "           1       0.71      0.77      0.74        31\n",
      "\n",
      "    accuracy                           0.81        90\n",
      "   macro avg       0.79      0.80      0.80        90\n",
      "weighted avg       0.82      0.81      0.81        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31177955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111111111111111"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7420f7",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e737a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14b9156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn=KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1dc3243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb0e431c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6333333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9be2d5",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fff8e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "812a901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "402688f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6937f107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6555555555555556"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d7c8a3",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35ee6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e042e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran1=RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43f718f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41d07cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran1.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64721061",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59bcdd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\youtech bd\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\youtech bd\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\youtech bd\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.22.4)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c2716a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64b0b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6067f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "222454f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04774889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444444444444444"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ebe1b",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05ca766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trees=np.random.randint(15,200,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4932e6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([130,  24,  24, 182,  64, 128,  16, 121,  49,  15,  38,  67,  61,\n",
       "        82, 114,  30,  34,  87, 109, 152,  18,  85,  89, 126, 112])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32aed4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=[\"gini\", \"entropy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0fcc9f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split=np.random.randint(1,3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5eaed419",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf=[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddfffecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=['sqrt','log2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ae7f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "grids={\n",
    "    'n_estimators':total_trees,\n",
    "    'criterion':criterion,\n",
    "    'min_samples_split':min_samples_split,\n",
    "    'min_samples_leaf':min_samples_leaf,\n",
    "    'max_features':max_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b34b765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': array([130,  24,  24, 182,  64, 128,  16, 121,  49,  15,  38,  67,  61,\n",
      "        82, 114,  30,  34,  87, 109, 152,  18,  85,  89, 126, 112]), 'criterion': ['gini', 'entropy'], 'min_samples_split': array([2, 1, 1, 2, 2, 2, 1, 1, 2, 2]), 'min_samples_leaf': [1, 2], 'max_features': ['sqrt', 'log2']}\n"
     ]
    }
   ],
   "source": [
    "print(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4c612c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5c2e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "rando=RandomizedSearchCV(estimator=ran1,param_distributions=grids,n_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69115df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(), n_iter=200,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                                        &#x27;min_samples_split&#x27;: array([2, 1, 1, 2, 2, 2, 1, 1, 2, 2]),\n",
       "                                        &#x27;n_estimators&#x27;: array([130,  24,  24, 182,  64, 128,  16, 121,  49,  15,  38,  67,  61,\n",
       "        82, 114,  30,  34,  87, 109, 152,  18,  85,  89, 126, 112])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(), n_iter=200,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                                        &#x27;min_samples_split&#x27;: array([2, 1, 1, 2, 2, 2, 1, 1, 2, 2]),\n",
       "                                        &#x27;n_estimators&#x27;: array([130,  24,  24, 182,  64, 128,  16, 121,  49,  15,  38,  67,  61,\n",
       "        82, 114,  30,  34,  87, 109, 152,  18,  85,  89, 126, 112])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(), n_iter=200,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2],\n",
       "                                        'min_samples_split': array([2, 1, 1, 2, 2, 2, 1, 1, 2, 2]),\n",
       "                                        'n_estimators': array([130,  24,  24, 182,  64, 128,  16, 121,  49,  15,  38,  67,  61,\n",
       "        82, 114,  30,  34,  87, 109, 152,  18,  85,  89, 126, 112])})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc9cea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "375 fits failed out of a total of 1000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "375 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Youtech BD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.85644599 0.870964   0.84703833 0.83739837\n",
      " 0.84227642 0.85667828 0.85168409 0.84703833 0.85168409        nan\n",
      " 0.85168409        nan 0.84216028 0.85180023 0.84216028        nan\n",
      "        nan 0.85667828        nan        nan 0.84692218 0.85644599\n",
      " 0.84692218 0.84204413 0.83739837        nan 0.85656214        nan\n",
      " 0.84227642 0.86608595        nan 0.82775842 0.85656214        nan\n",
      "        nan        nan 0.84216028        nan 0.86608595 0.85191638\n",
      " 0.83739837 0.85180023        nan 0.86144019 0.86620209        nan\n",
      " 0.85656214 0.85656214 0.84216028        nan 0.86608595        nan\n",
      "        nan 0.86144019 0.84703833        nan 0.82775842 0.85656214\n",
      " 0.85180023        nan 0.86132404 0.85656214 0.85656214 0.86132404\n",
      "        nan        nan 0.86132404        nan 0.85180023 0.85656214\n",
      " 0.84715447        nan 0.85168409        nan 0.84227642        nan\n",
      "        nan 0.83739837        nan 0.84227642 0.86132404 0.84216028\n",
      " 0.85667828 0.84703833 0.85656214 0.83728223 0.84216028        nan\n",
      " 0.82276423        nan        nan 0.86608595 0.84692218        nan\n",
      " 0.8659698  0.83739837        nan 0.84692218        nan        nan\n",
      " 0.84703833 0.84216028 0.85644599 0.85180023        nan 0.86620209\n",
      " 0.83275261 0.84692218 0.86144019        nan 0.82799071 0.8612079\n",
      "        nan 0.86608595 0.84227642 0.86144019        nan        nan\n",
      "        nan 0.86132404        nan 0.83263647        nan        nan\n",
      " 0.86608595 0.86132404 0.84239257 0.82299652        nan        nan\n",
      "        nan        nan 0.85644599 0.85180023 0.87084785 0.84680604\n",
      " 0.86620209        nan 0.8757259         nan        nan        nan\n",
      " 0.84703833 0.85168409 0.84227642        nan        nan 0.85180023\n",
      " 0.85168409 0.85667828 0.85168409 0.84204413 0.84680604 0.84692218\n",
      " 0.86132404        nan 0.85656214        nan 0.870964   0.86132404\n",
      " 0.85168409        nan 0.85180023        nan 0.84703833 0.85656214\n",
      "        nan        nan        nan 0.83751452 0.85644599        nan\n",
      " 0.86132404 0.86144019 0.86144019 0.84703833        nan        nan\n",
      " 0.84715447        nan 0.85156794 0.83728223        nan 0.85656214\n",
      "        nan        nan        nan        nan        nan 0.85180023\n",
      "        nan 0.84703833 0.87084785 0.84216028 0.84227642 0.83252033\n",
      " 0.85667828        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(), n_iter=200,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                                        &#x27;min_samples_split&#x27;: array([2, 1, 1, 2, 2, 2, 1, 1, 2, 2]),\n",
       "                                        &#x27;n_estimators&#x27;: array([130,  24,  24, 182,  64, 128,  16, 121,  49,  15,  38,  67,  61,\n",
       "        82, 114,  30,  34,  87, 109, 152,  18,  85,  89, 126, 112])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(), n_iter=200,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                                        &#x27;min_samples_split&#x27;: array([2, 1, 1, 2, 2, 2, 1, 1, 2, 2]),\n",
       "                                        &#x27;n_estimators&#x27;: array([130,  24,  24, 182,  64, 128,  16, 121,  49,  15,  38,  67,  61,\n",
       "        82, 114,  30,  34,  87, 109, 152,  18,  85,  89, 126, 112])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(), n_iter=200,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2],\n",
       "                                        'min_samples_split': array([2, 1, 1, 2, 2, 2, 1, 1, 2, 2]),\n",
       "                                        'n_estimators': array([130,  24,  24, 182,  64, 128,  16, 121,  49,  15,  38,  67,  61,\n",
       "        82, 114,  30,  34,  87, 109, 152,  18,  85,  89, 126, 112])})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b16f2305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 85,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'log2',\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff8eaa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01615644, 0.05306563, 0.09232435, 0.12648807, 0.09615374,\n",
       "        0.02633653, 0.12899957, 0.12450714, 0.08916364, 0.02333541,\n",
       "        0.08654618, 0.03301249, 0.08413439, 0.06385212, 0.11549048,\n",
       "        0.15270576, 0.18702669, 0.03903008, 0.03212457, 0.24714851,\n",
       "        0.10359259, 0.06863575, 0.0442759 , 0.21298981, 0.1811265 ,\n",
       "        0.02254291, 0.03350329, 0.04929461, 0.2439642 , 0.0583168 ,\n",
       "        0.26728864, 0.17778735, 0.07982473, 0.08620028, 0.25282054,\n",
       "        0.0135695 , 0.05555863, 0.02373672, 0.21150675, 0.08087177,\n",
       "        0.12690697, 0.12796583, 0.02771959, 0.0845758 , 0.00947661,\n",
       "        0.18271527, 0.26817737, 0.03272176, 0.10741515, 0.19652982,\n",
       "        0.040802  , 0.0145689 , 0.13980107, 0.019349  , 0.03524928,\n",
       "        0.07947407, 0.1184978 , 0.05026536, 0.09584117, 0.13649001,\n",
       "        0.02733469, 0.06567721, 0.15587173, 0.12935433, 0.09686513,\n",
       "        0.21991382, 0.06981564, 0.03352294, 0.16892066, 0.03271432,\n",
       "        0.12847695, 0.22750597, 0.03859487, 0.01934981, 0.07204137,\n",
       "        0.01017251, 0.04220881, 0.00958343, 0.0069737 , 0.0396812 ,\n",
       "        0.04538059, 0.10803256, 0.17176781, 0.04999032, 0.06394286,\n",
       "        0.13560319, 0.11681929, 0.03789635, 0.1190249 , 0.03382678,\n",
       "        0.03988767, 0.01456175, 0.04807148, 0.17057104, 0.0261354 ,\n",
       "        0.02273912, 0.18492403, 0.04479523, 0.04518409, 0.18093853,\n",
       "        0.01336389, 0.03421025, 0.12830267, 0.11916633, 0.1238853 ,\n",
       "        0.07836442, 0.04449368, 0.05345092, 0.05465484, 0.07580628,\n",
       "        0.13250546, 0.01878266, 0.08343329, 0.07280555, 0.00907788,\n",
       "        0.24565201, 0.03769226, 0.10032997, 0.01017199, 0.04697618,\n",
       "        0.00916257, 0.18717031, 0.04387641, 0.03900256, 0.01137033,\n",
       "        0.01137071, 0.13857574, 0.10222893, 0.0297205 , 0.0470736 ,\n",
       "        0.02444134, 0.04979243, 0.01945763, 0.00787406, 0.17191691,\n",
       "        0.04527745, 0.1684588 , 0.10542383, 0.18738899, 0.02765012,\n",
       "        0.12374706, 0.01396127, 0.06513634, 0.01037211, 0.09235706,\n",
       "        0.10208826, 0.05556297, 0.05585089, 0.03919768, 0.3166996 ,\n",
       "        0.13006353, 0.30471649, 0.14682164, 0.02752633, 0.12058411,\n",
       "        0.19423065, 0.16088614, 0.05007257, 0.16516728, 0.00838394,\n",
       "        0.16665778, 0.1861331 , 0.17412186, 0.01057186, 0.12055545,\n",
       "        0.05665302, 0.27052965, 0.26688576, 0.05805249, 0.00928588,\n",
       "        0.00796499, 0.12965789, 0.04817967, 0.03381686, 0.19325924,\n",
       "        0.03809838, 0.0439095 , 0.03930573, 0.01795888, 0.01346617,\n",
       "        0.18602743, 0.01496644, 0.07274342, 0.02693553, 0.0348093 ,\n",
       "        0.19238081, 0.01516008, 0.00838408, 0.0292388 , 0.02215066,\n",
       "        0.02454133, 0.1260561 , 0.03330965, 0.09863229, 0.07147427,\n",
       "        0.09694548, 0.03630204, 0.02972078, 0.12134905, 0.03679757]),\n",
       " 'std_fit_time': array([4.00907586e-03, 3.12024822e-03, 9.63175181e-03, 1.60436951e-02,\n",
       "        2.86008168e-03, 4.52530363e-03, 4.11093903e-03, 3.45898289e-03,\n",
       "        3.80320227e-03, 1.02925277e-03, 7.46780555e-03, 1.00983450e-03,\n",
       "        5.56304233e-03, 5.35442453e-03, 5.57528210e-02, 8.36162659e-03,\n",
       "        2.85999561e-02, 3.11154847e-03, 2.23483276e-03, 1.55504636e-01,\n",
       "        4.73069945e-02, 8.01072343e-03, 7.78019853e-03, 5.73579513e-02,\n",
       "        1.90888911e-02, 4.91991083e-04, 2.05363162e-03, 4.44722884e-03,\n",
       "        6.44233582e-02, 9.18798974e-03, 7.38810376e-02, 1.18924673e-02,\n",
       "        4.27794742e-02, 6.33057308e-03, 3.41426897e-02, 3.60780864e-03,\n",
       "        1.34941065e-02, 3.75316051e-03, 5.42421764e-02, 1.12258278e-02,\n",
       "        1.17991903e-02, 6.09706669e-03, 2.99353066e-03, 8.53870683e-03,\n",
       "        8.89547501e-04, 9.63247587e-03, 6.51740970e-02, 5.43313918e-03,\n",
       "        1.17148702e-02, 3.84005993e-03, 3.66433557e-03, 3.38796020e-03,\n",
       "        1.13417437e-02, 4.42465548e-03, 2.79239647e-03, 2.30459745e-03,\n",
       "        7.31065612e-03, 5.66342215e-03, 5.94782864e-03, 4.21993116e-03,\n",
       "        1.02968734e-03, 4.36587354e-03, 9.44692632e-03, 1.03194664e-02,\n",
       "        2.53826306e-03, 3.41102469e-02, 4.11143811e-03, 5.88602221e-03,\n",
       "        1.06587803e-02, 1.73396886e-03, 6.67880200e-03, 2.95000369e-03,\n",
       "        2.80752686e-03, 8.07919594e-04, 2.54986591e-03, 2.39430697e-03,\n",
       "        2.56903420e-03, 4.74246555e-04, 6.30976333e-04, 3.29163478e-03,\n",
       "        9.76193914e-03, 5.09778068e-03, 6.72524979e-03, 2.02280437e-03,\n",
       "        3.21305902e-03, 9.76521614e-03, 7.02299317e-03, 3.50281552e-03,\n",
       "        4.80608113e-03, 4.60570134e-03, 3.52011478e-03, 3.25117961e-03,\n",
       "        2.47603800e-03, 4.37869016e-03, 1.56265035e-03, 5.12152800e-03,\n",
       "        1.72740072e-02, 8.16440541e-04, 2.77228383e-03, 4.22352809e-03,\n",
       "        4.74451472e-04, 2.22190388e-03, 4.68266028e-03, 5.73106919e-03,\n",
       "        3.64006297e-03, 1.15210313e-02, 4.12079046e-03, 3.66439778e-03,\n",
       "        2.22160923e-03, 3.39175534e-03, 2.38556339e-03, 7.05597944e-04,\n",
       "        3.90383866e-03, 5.49916639e-03, 6.63154300e-04, 2.45678846e-02,\n",
       "        1.92907157e-03, 4.61685966e-03, 2.55442518e-03, 3.03156154e-03,\n",
       "        1.16028761e-03, 1.46727458e-02, 2.61237447e-03, 4.20376206e-03,\n",
       "        7.98154794e-04, 4.88291713e-04, 5.94484732e-03, 3.63351314e-03,\n",
       "        4.29693507e-03, 1.93376257e-03, 1.16975235e-03, 3.58462415e-03,\n",
       "        1.07338009e-03, 9.05335835e-04, 1.29366860e-02, 2.16340335e-03,\n",
       "        7.54545054e-03, 5.14068607e-03, 1.78021394e-02, 1.08875581e-03,\n",
       "        1.05007449e-02, 6.31506009e-04, 2.81029318e-03, 4.87974269e-04,\n",
       "        9.55503341e-03, 3.51686754e-03, 2.54063632e-03, 4.92662242e-03,\n",
       "        6.19637565e-03, 3.30520386e-02, 1.75349979e-03, 4.44987014e-02,\n",
       "        1.03613390e-02, 1.73938027e-03, 3.96013389e-03, 3.28785739e-03,\n",
       "        7.51808556e-03, 2.70587190e-03, 1.37791202e-02, 8.02840322e-04,\n",
       "        4.33688283e-03, 4.47857840e-03, 1.33640764e-02, 1.35364025e-03,\n",
       "        3.89678162e-03, 3.23279597e-03, 5.88417609e-03, 3.83656543e-02,\n",
       "        3.31087609e-03, 1.57842602e-03, 2.86283436e-05, 6.05750598e-03,\n",
       "        6.52065219e-03, 1.48570873e-03, 8.63291932e-03, 5.02289024e-03,\n",
       "        2.08809427e-03, 9.74781297e-04, 9.00103212e-04, 1.93708747e-03,\n",
       "        3.55757089e-03, 2.81234635e-03, 4.05676632e-03, 4.03710791e-03,\n",
       "        1.19543656e-03, 3.68367350e-03, 7.46879921e-04, 7.76523955e-04,\n",
       "        8.75266311e-04, 7.56708203e-04, 3.81567942e-03, 7.80896101e-03,\n",
       "        4.89361453e-03, 6.18427734e-03, 3.90555735e-03, 2.69763127e-03,\n",
       "        7.97415557e-04, 1.92003440e-03, 6.88949834e-03, 3.27721265e-03]),\n",
       " 'mean_score_time': array([0.        , 0.        , 0.00938945, 0.01436114, 0.00976787,\n",
       "        0.0033905 , 0.01172729, 0.01236739, 0.00857577, 0.00369539,\n",
       "        0.00857019, 0.        , 0.00936871, 0.        , 0.00877824,\n",
       "        0.01317105, 0.01916184, 0.        , 0.        , 0.03321719,\n",
       "        0.        , 0.        , 0.00618238, 0.02633123, 0.01656909,\n",
       "        0.00335712, 0.00439601, 0.        , 0.02033906, 0.        ,\n",
       "        0.03790503, 0.0151576 , 0.        , 0.00937428, 0.02054353,\n",
       "        0.        , 0.        , 0.        , 0.0205452 , 0.        ,\n",
       "        0.01108341, 0.01227598, 0.00438771, 0.00957518, 0.        ,\n",
       "        0.01647954, 0.02234206, 0.        , 0.01237388, 0.01615624,\n",
       "        0.00518713, 0.        , 0.01416588, 0.        , 0.        ,\n",
       "        0.00801806, 0.01028385, 0.        , 0.00977306, 0.01294909,\n",
       "        0.00439582, 0.        , 0.01292043, 0.0123745 , 0.00897613,\n",
       "        0.01895084, 0.        , 0.        , 0.01614203, 0.        ,\n",
       "        0.01278105, 0.02075849, 0.00478635, 0.        , 0.00717759,\n",
       "        0.        , 0.00458918, 0.        , 0.        , 0.00460057,\n",
       "        0.        , 0.00938025, 0.01535249, 0.00498691, 0.00617638,\n",
       "        0.01274228, 0.01017871, 0.00498867, 0.01136389, 0.        ,\n",
       "        0.00558681, 0.        , 0.        , 0.01446285, 0.00299201,\n",
       "        0.        , 0.01674819, 0.00537758, 0.        , 0.01635733,\n",
       "        0.        , 0.        , 0.01134415, 0.01117773, 0.012958  ,\n",
       "        0.00738444, 0.        , 0.00538611, 0.00618258, 0.007373  ,\n",
       "        0.01298127, 0.        , 0.00776458, 0.00777879, 0.        ,\n",
       "        0.01905222, 0.00519414, 0.00957413, 0.        , 0.        ,\n",
       "        0.        , 0.01654181, 0.        , 0.00498652, 0.        ,\n",
       "        0.        , 0.0127583 , 0.00877695, 0.00458779, 0.00498757,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01474886,\n",
       "        0.00478029, 0.01497364, 0.00917521, 0.01570392, 0.        ,\n",
       "        0.0115634 , 0.        , 0.        , 0.        , 0.00857716,\n",
       "        0.00938296, 0.00597649, 0.        , 0.        , 0.02253876,\n",
       "        0.01097841, 0.02552452, 0.01275845, 0.00458794, 0.01177816,\n",
       "        0.01634202, 0.01436195, 0.        , 0.01356144, 0.        ,\n",
       "        0.01366673, 0.01554251, 0.01415043, 0.        , 0.01097145,\n",
       "        0.        , 0.02254076, 0.02184286, 0.        , 0.        ,\n",
       "        0.        , 0.01017275, 0.00518575, 0.        , 0.01525507,\n",
       "        0.00578475, 0.00556984, 0.00478005, 0.        , 0.        ,\n",
       "        0.01476307, 0.        , 0.00720062, 0.00379081, 0.        ,\n",
       "        0.01536546, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01115708, 0.        , 0.0089829 , 0.00777221,\n",
       "        0.00917654, 0.00458841, 0.00359039, 0.01035857, 0.        ]),\n",
       " 'std_score_time': array([0.00000000e+00, 0.00000000e+00, 1.96936661e-03, 3.18770251e-03,\n",
       "        7.53222722e-04, 4.74918161e-04, 1.75689481e-03, 2.05353500e-03,\n",
       "        4.74199213e-04, 3.83087798e-04, 4.97594803e-04, 0.00000000e+00,\n",
       "        1.49001711e-03, 0.00000000e+00, 7.35974274e-04, 4.13978108e-04,\n",
       "        5.32340749e-03, 0.00000000e+00, 0.00000000e+00, 2.56538318e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.62877242e-03, 1.16776123e-02,\n",
       "        3.75368834e-03, 5.39337215e-04, 4.84152081e-04, 0.00000000e+00,\n",
       "        8.21706734e-03, 0.00000000e+00, 3.52149214e-02, 3.06462943e-03,\n",
       "        0.00000000e+00, 1.62446185e-03, 2.64548466e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.65632331e-03, 0.00000000e+00,\n",
       "        3.21281360e-03, 2.88163883e-03, 7.98058658e-04, 2.41114173e-03,\n",
       "        0.00000000e+00, 1.61881283e-03, 4.64969836e-03, 0.00000000e+00,\n",
       "        2.72942539e-03, 1.46652465e-03, 9.77456598e-04, 0.00000000e+00,\n",
       "        3.42760461e-03, 0.00000000e+00, 0.00000000e+00, 5.49436770e-04,\n",
       "        4.04254449e-04, 0.00000000e+00, 2.63065180e-03, 1.66597726e-03,\n",
       "        1.02150941e-03, 0.00000000e+00, 7.72845648e-04, 2.40721921e-03,\n",
       "        6.30450814e-04, 3.73091106e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.95054034e-03, 0.00000000e+00, 2.71436235e-03, 1.83259634e-03,\n",
       "        3.98088883e-04, 0.00000000e+00, 7.42933640e-04, 0.00000000e+00,\n",
       "        4.72296231e-04, 0.00000000e+00, 0.00000000e+00, 4.99406546e-04,\n",
       "        0.00000000e+00, 1.36343681e-03, 1.85497639e-03, 6.84390073e-07,\n",
       "        4.01754721e-04, 1.59279841e-03, 7.44536883e-04, 6.27435607e-04,\n",
       "        4.92571298e-04, 0.00000000e+00, 1.84790325e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00188311e-03, 8.60951905e-07, 0.00000000e+00,\n",
       "        2.22764710e-03, 7.83658164e-04, 0.00000000e+00, 1.01706552e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.11287393e-04, 1.14841227e-03,\n",
       "        2.28002850e-03, 4.83734872e-04, 0.00000000e+00, 4.89106380e-04,\n",
       "        7.46762685e-04, 8.01851407e-04, 1.27476272e-03, 0.00000000e+00,\n",
       "        3.91947382e-04, 2.12930791e-03, 0.00000000e+00, 7.93564347e-04,\n",
       "        9.89470854e-04, 7.98501550e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.84298913e-03, 0.00000000e+00, 1.09236234e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.47804708e-03, 9.77486789e-04,\n",
       "        7.97643295e-04, 1.26698782e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.43891480e-04, 3.95517467e-04,\n",
       "        1.78485206e-03, 7.47266930e-04, 1.87841780e-03, 0.00000000e+00,\n",
       "        4.98987055e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.23942837e-03, 1.35015084e-03, 8.83789102e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.71951953e-03, 1.62386682e-05, 4.35668433e-03,\n",
       "        1.59412164e-03, 1.01737376e-03, 2.22212732e-03, 2.85097863e-03,\n",
       "        2.32649575e-03, 0.00000000e+00, 1.01757509e-03, 0.00000000e+00,\n",
       "        6.02023438e-04, 2.72927406e-03, 7.42605597e-04, 0.00000000e+00,\n",
       "        6.30300837e-04, 0.00000000e+00, 1.49282095e-03, 3.04333490e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.98804250e-04,\n",
       "        7.46060241e-04, 0.00000000e+00, 7.42532510e-04, 1.16274554e-03,\n",
       "        4.92225342e-04, 4.11868768e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.00652399e-04, 0.00000000e+00, 9.81502008e-04, 7.47360713e-04,\n",
       "        0.00000000e+00, 4.83546091e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.89912383e-04,\n",
       "        0.00000000e+00, 1.10334474e-03, 9.82091790e-04, 1.95228745e-03,\n",
       "        4.89045742e-04, 4.88850222e-04, 5.00358661e-04, 0.00000000e+00]),\n",
       " 'param_n_estimators': masked_array(data=[38, 152, 61, 87, 67, 15, 89, 87, 64, 15, 61, 109, 64,\n",
       "                    182, 61, 109, 114, 85, 89, 82, 114, 112, 18, 89, 114,\n",
       "                    16, 24, 126, 112, 126, 130, 85, 82, 24, 128, 18, 85,\n",
       "                    34, 112, 114, 64, 82, 16, 49, 18, 121, 126, 64, 67,\n",
       "                    126, 24, 30, 85, 34, 89, 61, 82, 128, 61, 89, 18, 182,\n",
       "                    112, 89, 67, 126, 182, 64, 121, 87, 85, 152, 24, 49,\n",
       "                    49, 18, 30, 24, 15, 30, 109, 67, 114, 34, 38, 87, 85,\n",
       "                    24, 82, 85, 24, 24, 126, 112, 16, 49, 130, 30, 121,\n",
       "                    121, 30, 87, 87, 87, 87, 49, 112, 34, 34, 49, 89, 49,\n",
       "                    64, 49, 18, 152, 24, 67, 18, 126, 18, 128, 112, 24, 24,\n",
       "                    24, 87, 67, 18, 30, 61, 130, 49, 16, 126, 30, 112, 67,\n",
       "                    128, 87, 85, 34, 182, 24, 61, 67, 34, 126, 89, 182, 89,\n",
       "                    182, 109, 18, 82, 130, 109, 152, 121, 15, 109, 121,\n",
       "                    126, 24, 85, 152, 182, 182, 152, 15, 16, 87, 30, 87,\n",
       "                    130, 24, 34, 30, 49, 30, 128, 30, 49, 16, 89, 130, 38,\n",
       "                    18, 89, 67, 67, 85, 85, 64, 49, 64, 24, 18, 87, 109],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1,\n",
       "                    1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1,\n",
       "                    1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1,\n",
       "                    1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2,\n",
       "                    2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "                    2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2,\n",
       "                    2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1,\n",
       "                    2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1,\n",
       "                    2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2,\n",
       "                    2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1,\n",
       "                    2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2,\n",
       "                    2, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1,\n",
       "                    1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2,\n",
       "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2,\n",
       "                    1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1,\n",
       "                    1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1,\n",
       "                    2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "                    1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1,\n",
       "                    2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2,\n",
       "                    2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1,\n",
       "                    1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1,\n",
       "                    1, 2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['sqrt', 'log2', 'log2', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'log2', 'sqrt', 'log2', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'log2', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'sqrt', 'log2', 'sqrt', 'log2', 'sqrt', 'log2',\n",
       "                    'sqrt', 'log2', 'sqrt', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'log2', 'sqrt', 'sqrt', 'sqrt', 'log2', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'log2', 'log2', 'sqrt', 'log2', 'sqrt', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2', 'sqrt', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'log2', 'sqrt', 'sqrt', 'log2', 'log2', 'sqrt',\n",
       "                    'log2', 'log2', 'sqrt', 'log2', 'sqrt', 'log2', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                    'sqrt', 'log2', 'sqrt', 'sqrt', 'log2', 'sqrt', 'log2',\n",
       "                    'sqrt', 'log2', 'sqrt', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'sqrt', 'log2', 'sqrt',\n",
       "                    'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
       "                    'log2', 'log2', 'log2', 'sqrt', 'log2', 'sqrt', 'sqrt',\n",
       "                    'log2', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'log2', 'sqrt', 'log2', 'sqrt',\n",
       "                    'log2', 'log2', 'sqrt', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', 'sqrt'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'gini', 'entropy', 'gini',\n",
       "                    'entropy', 'gini', 'entropy', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'gini', 'gini',\n",
       "                    'gini', 'entropy', 'gini', 'entropy', 'gini', 'gini',\n",
       "                    'entropy', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'gini', 'gini', 'entropy', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'gini',\n",
       "                    'entropy', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'gini', 'entropy', 'gini',\n",
       "                    'entropy', 'entropy', 'gini', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'gini', 'entropy', 'gini', 'entropy',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'entropy', 'gini',\n",
       "                    'entropy', 'gini', 'entropy', 'entropy', 'gini',\n",
       "                    'gini', 'gini', 'entropy', 'gini', 'gini', 'entropy',\n",
       "                    'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'gini', 'entropy', 'gini',\n",
       "                    'gini', 'entropy', 'entropy', 'gini', 'gini',\n",
       "                    'entropy', 'gini', 'gini', 'entropy', 'gini', 'gini',\n",
       "                    'gini', 'entropy', 'entropy', 'entropy', 'gini',\n",
       "                    'gini', 'gini', 'entropy', 'entropy', 'gini', 'gini',\n",
       "                    'gini', 'entropy', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'gini', 'entropy',\n",
       "                    'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'gini', 'gini', 'gini', 'entropy', 'gini',\n",
       "                    'gini', 'entropy', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'entropy', 'gini',\n",
       "                    'entropy', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'entropy', 'gini', 'entropy', 'gini'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 38,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 152,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 61,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 67,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 64,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 61,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 109,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 64,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 182,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 61,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 109,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 114,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 82,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 114,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 112,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 114,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 126,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 112,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 126,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 130,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 82,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 128,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 112,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 114,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 64,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 82,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 121,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 126,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 64,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 67,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 126,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 61,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 82,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 128,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 61,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 182,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 112,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 67,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 126,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 182,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 64,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 121,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 152,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 15,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 109,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 67,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 114,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 38,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 82,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 126,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 112,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 130,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 121,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 121,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 112,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 64,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 152,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 67,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 126,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 128,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 112,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 67,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 61,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 130,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 16,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 126,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 112,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 67,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 128,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 182,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 61,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 67,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 126,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 182,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 182,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 109,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 82,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 130,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 109,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 152,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 121,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 15,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 109,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 121,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 126,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 152,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 182,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 182,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 152,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 15,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 16,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 130,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 34,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 128,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 30,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 16,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 130,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 38,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 89,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 67,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 67,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 85,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 64,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 49,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 64,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 24,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 18,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_features': 'log2',\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 109,\n",
       "   'min_samples_split': 1,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_features': 'sqrt',\n",
       "   'criterion': 'gini'}],\n",
       " 'split0_test_score': array([       nan,        nan, 0.88095238, 0.9047619 , 0.85714286,\n",
       "        0.85714286, 0.80952381, 0.85714286, 0.88095238, 0.9047619 ,\n",
       "        0.85714286,        nan, 0.88095238,        nan, 0.83333333,\n",
       "        0.85714286, 0.85714286,        nan,        nan, 0.83333333,\n",
       "               nan,        nan, 0.85714286, 0.88095238, 0.88095238,\n",
       "        0.80952381, 0.88095238,        nan, 0.9047619 ,        nan,\n",
       "        0.83333333, 0.85714286,        nan, 0.83333333, 0.85714286,\n",
       "               nan,        nan,        nan, 0.85714286,        nan,\n",
       "        0.88095238, 0.85714286, 0.83333333, 0.88095238,        nan,\n",
       "        0.88095238, 0.88095238,        nan, 0.83333333, 0.88095238,\n",
       "        0.85714286,        nan, 0.88095238,        nan,        nan,\n",
       "        0.80952381, 0.83333333,        nan, 0.85714286, 0.88095238,\n",
       "        0.85714286,        nan, 0.88095238, 0.85714286, 0.85714286,\n",
       "        0.85714286,        nan,        nan, 0.88095238,        nan,\n",
       "        0.80952381, 0.83333333, 0.85714286,        nan, 0.88095238,\n",
       "               nan, 0.88095238,        nan,        nan, 0.85714286,\n",
       "               nan, 0.83333333, 0.85714286, 0.83333333, 0.85714286,\n",
       "        0.85714286, 0.88095238, 0.85714286, 0.85714286,        nan,\n",
       "        0.85714286,        nan,        nan, 0.88095238, 0.83333333,\n",
       "               nan, 0.9047619 , 0.85714286,        nan, 0.88095238,\n",
       "               nan,        nan, 0.83333333, 0.85714286, 0.85714286,\n",
       "        0.85714286,        nan, 0.85714286, 0.80952381, 0.85714286,\n",
       "        0.85714286,        nan, 0.83333333, 0.85714286,        nan,\n",
       "        0.88095238, 0.78571429, 0.83333333,        nan,        nan,\n",
       "               nan, 0.85714286,        nan, 0.85714286,        nan,\n",
       "               nan, 0.85714286, 0.88095238, 0.85714286, 0.78571429,\n",
       "               nan,        nan,        nan,        nan, 0.88095238,\n",
       "        0.88095238, 0.88095238, 0.85714286, 0.85714286,        nan,\n",
       "        0.88095238,        nan,        nan,        nan, 0.83333333,\n",
       "        0.85714286, 0.85714286,        nan,        nan, 0.88095238,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.83333333, 0.88095238,\n",
       "        0.88095238, 0.88095238,        nan, 0.85714286,        nan,\n",
       "        0.88095238, 0.85714286, 0.88095238,        nan, 0.85714286,\n",
       "               nan, 0.83333333, 0.88095238,        nan,        nan,\n",
       "               nan, 0.80952381, 0.88095238,        nan, 0.88095238,\n",
       "        0.83333333, 0.83333333, 0.83333333,        nan,        nan,\n",
       "        0.88095238,        nan, 0.85714286, 0.83333333,        nan,\n",
       "        0.88095238,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.83333333,        nan, 0.80952381, 0.88095238,\n",
       "        0.83333333, 0.85714286, 0.80952381, 0.85714286,        nan]),\n",
       " 'split1_test_score': array([       nan,        nan, 0.80952381, 0.80952381, 0.78571429,\n",
       "        0.85714286, 0.83333333, 0.83333333, 0.80952381, 0.80952381,\n",
       "        0.83333333,        nan, 0.80952381,        nan, 0.80952381,\n",
       "        0.80952381, 0.83333333,        nan,        nan, 0.85714286,\n",
       "               nan,        nan, 0.80952381, 0.80952381, 0.80952381,\n",
       "        0.85714286, 0.80952381,        nan, 0.80952381,        nan,\n",
       "        0.83333333, 0.85714286,        nan, 0.83333333, 0.80952381,\n",
       "               nan,        nan,        nan, 0.83333333,        nan,\n",
       "        0.83333333, 0.80952381, 0.85714286, 0.78571429,        nan,\n",
       "        0.80952381, 0.80952381,        nan, 0.83333333, 0.83333333,\n",
       "        0.83333333,        nan, 0.85714286,        nan,        nan,\n",
       "        0.85714286, 0.80952381,        nan, 0.78571429, 0.80952381,\n",
       "        0.83333333,        nan, 0.83333333, 0.83333333, 0.83333333,\n",
       "        0.83333333,        nan,        nan, 0.80952381,        nan,\n",
       "        0.85714286, 0.85714286, 0.85714286,        nan, 0.85714286,\n",
       "               nan, 0.83333333,        nan,        nan, 0.78571429,\n",
       "               nan, 0.80952381, 0.85714286, 0.83333333, 0.80952381,\n",
       "        0.78571429, 0.80952381, 0.80952381, 0.80952381,        nan,\n",
       "        0.80952381,        nan,        nan, 0.83333333, 0.78571429,\n",
       "               nan, 0.83333333, 0.80952381,        nan, 0.80952381,\n",
       "               nan,        nan, 0.80952381, 0.80952381, 0.85714286,\n",
       "        0.83333333,        nan, 0.85714286, 0.85714286, 0.78571429,\n",
       "        0.85714286,        nan, 0.78571429, 0.85714286,        nan,\n",
       "        0.85714286, 0.83333333, 0.83333333,        nan,        nan,\n",
       "               nan, 0.83333333,        nan, 0.80952381,        nan,\n",
       "               nan, 0.83333333, 0.83333333, 0.80952381, 0.85714286,\n",
       "               nan,        nan,        nan,        nan, 0.80952381,\n",
       "        0.80952381, 0.83333333, 0.83333333, 0.83333333,        nan,\n",
       "        0.83333333,        nan,        nan,        nan, 0.78571429,\n",
       "        0.83333333, 0.80952381,        nan,        nan, 0.80952381,\n",
       "        0.83333333, 0.80952381, 0.80952381, 0.83333333, 0.80952381,\n",
       "        0.80952381, 0.83333333,        nan, 0.80952381,        nan,\n",
       "        0.83333333, 0.85714286, 0.80952381,        nan, 0.80952381,\n",
       "               nan, 0.80952381, 0.80952381,        nan,        nan,\n",
       "               nan, 0.83333333, 0.80952381,        nan, 0.83333333,\n",
       "        0.83333333, 0.80952381, 0.80952381,        nan,        nan,\n",
       "        0.80952381,        nan, 0.83333333, 0.85714286,        nan,\n",
       "        0.80952381,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.83333333,        nan, 0.83333333, 0.88095238,\n",
       "        0.78571429, 0.80952381, 0.83333333, 0.83333333,        nan]),\n",
       " 'split2_test_score': array([       nan,        nan, 0.9047619 , 0.92857143, 0.9047619 ,\n",
       "        0.88095238, 0.88095238, 0.9047619 , 0.9047619 , 0.88095238,\n",
       "        0.92857143,        nan, 0.9047619 ,        nan, 0.9047619 ,\n",
       "        0.9047619 , 0.85714286,        nan,        nan, 0.9047619 ,\n",
       "               nan,        nan, 0.9047619 , 0.92857143, 0.88095238,\n",
       "        0.92857143, 0.83333333,        nan, 0.88095238,        nan,\n",
       "        0.88095238, 0.9047619 ,        nan, 0.78571429, 0.92857143,\n",
       "               nan,        nan,        nan, 0.85714286,        nan,\n",
       "        0.92857143, 0.88095238, 0.85714286, 0.9047619 ,        nan,\n",
       "        0.9047619 , 0.92857143,        nan, 0.9047619 , 0.88095238,\n",
       "        0.9047619 ,        nan, 0.88095238,        nan,        nan,\n",
       "        0.92857143, 0.9047619 ,        nan, 0.85714286, 0.9047619 ,\n",
       "        0.88095238,        nan, 0.9047619 , 0.9047619 , 0.9047619 ,\n",
       "        0.9047619 ,        nan,        nan, 0.9047619 ,        nan,\n",
       "        0.9047619 , 0.9047619 , 0.83333333,        nan, 0.88095238,\n",
       "               nan, 0.85714286,        nan,        nan, 0.88095238,\n",
       "               nan, 0.9047619 , 0.88095238, 0.92857143, 0.92857143,\n",
       "        0.9047619 , 0.9047619 , 0.88095238, 0.88095238,        nan,\n",
       "        0.88095238,        nan,        nan, 0.9047619 , 0.92857143,\n",
       "               nan, 0.92857143, 0.85714286,        nan, 0.88095238,\n",
       "               nan,        nan, 0.9047619 , 0.88095238, 0.9047619 ,\n",
       "        0.88095238,        nan, 0.9047619 , 0.85714286, 0.9047619 ,\n",
       "        0.88095238,        nan, 0.83333333, 0.92857143,        nan,\n",
       "        0.88095238, 0.92857143, 0.9047619 ,        nan,        nan,\n",
       "               nan, 0.92857143,        nan, 0.85714286,        nan,\n",
       "               nan, 0.92857143, 0.9047619 , 0.83333333, 0.88095238,\n",
       "               nan,        nan,        nan,        nan, 0.92857143,\n",
       "        0.9047619 , 0.92857143, 0.88095238, 0.92857143,        nan,\n",
       "        0.92857143,        nan,        nan,        nan, 0.92857143,\n",
       "        0.9047619 , 0.85714286,        nan,        nan, 0.88095238,\n",
       "        0.9047619 , 0.9047619 , 0.9047619 , 0.9047619 , 0.9047619 ,\n",
       "        0.88095238, 0.9047619 ,        nan, 0.9047619 ,        nan,\n",
       "        0.92857143, 0.9047619 , 0.92857143,        nan, 0.9047619 ,\n",
       "               nan, 0.9047619 , 0.9047619 ,        nan,        nan,\n",
       "               nan, 0.88095238, 0.9047619 ,        nan, 0.92857143,\n",
       "        0.92857143, 0.9047619 , 0.92857143,        nan,        nan,\n",
       "        0.88095238,        nan, 0.92857143, 0.85714286,        nan,\n",
       "        0.9047619 ,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.9047619 ,        nan, 0.9047619 , 0.9047619 ,\n",
       "        0.9047619 , 0.83333333, 0.85714286, 0.9047619 ,        nan]),\n",
       " 'split3_test_score': array([       nan,        nan, 0.83333333, 0.80952381, 0.80952381,\n",
       "        0.73809524, 0.80952381, 0.78571429, 0.80952381, 0.76190476,\n",
       "        0.78571429,        nan, 0.80952381,        nan, 0.80952381,\n",
       "        0.80952381, 0.80952381,        nan,        nan, 0.78571429,\n",
       "               nan,        nan, 0.80952381, 0.80952381, 0.80952381,\n",
       "        0.78571429, 0.80952381,        nan, 0.80952381,        nan,\n",
       "        0.78571429, 0.83333333,        nan, 0.85714286, 0.80952381,\n",
       "               nan,        nan,        nan, 0.80952381,        nan,\n",
       "        0.80952381, 0.80952381, 0.78571429, 0.80952381,        nan,\n",
       "        0.80952381, 0.80952381,        nan, 0.83333333, 0.80952381,\n",
       "        0.76190476,        nan, 0.83333333,        nan,        nan,\n",
       "        0.80952381, 0.80952381,        nan, 0.80952381, 0.80952381,\n",
       "        0.80952381,        nan, 0.80952381, 0.80952381, 0.80952381,\n",
       "        0.83333333,        nan,        nan, 0.83333333,        nan,\n",
       "        0.80952381, 0.80952381, 0.78571429,        nan, 0.78571429,\n",
       "               nan, 0.76190476,        nan,        nan, 0.80952381,\n",
       "               nan, 0.78571429, 0.83333333, 0.76190476, 0.78571429,\n",
       "        0.80952381, 0.80952381, 0.80952381, 0.80952381,        nan,\n",
       "        0.78571429,        nan,        nan, 0.83333333, 0.83333333,\n",
       "               nan, 0.80952381, 0.80952381,        nan, 0.80952381,\n",
       "               nan,        nan, 0.80952381, 0.80952381, 0.80952381,\n",
       "        0.80952381,        nan, 0.80952381, 0.76190476, 0.83333333,\n",
       "        0.80952381,        nan, 0.80952381, 0.80952381,        nan,\n",
       "        0.83333333, 0.78571429, 0.83333333,        nan,        nan,\n",
       "               nan, 0.80952381,        nan, 0.78571429,        nan,\n",
       "               nan, 0.83333333, 0.80952381, 0.80952381, 0.76190476,\n",
       "               nan,        nan,        nan,        nan, 0.80952381,\n",
       "        0.78571429, 0.83333333, 0.83333333, 0.80952381,        nan,\n",
       "        0.83333333,        nan,        nan,        nan, 0.80952381,\n",
       "        0.80952381, 0.80952381,        nan,        nan, 0.80952381,\n",
       "        0.80952381, 0.80952381, 0.83333333, 0.80952381, 0.80952381,\n",
       "        0.80952381, 0.80952381,        nan, 0.83333333,        nan,\n",
       "        0.80952381, 0.80952381, 0.78571429,        nan, 0.80952381,\n",
       "               nan, 0.80952381, 0.80952381,        nan,        nan,\n",
       "               nan, 0.78571429, 0.83333333,        nan, 0.78571429,\n",
       "        0.80952381, 0.85714286, 0.78571429,        nan,        nan,\n",
       "        0.76190476,        nan, 0.80952381, 0.80952381,        nan,\n",
       "        0.80952381,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.80952381,        nan, 0.80952381, 0.80952381,\n",
       "        0.83333333, 0.83333333, 0.83333333, 0.78571429,        nan]),\n",
       " 'split4_test_score': array([       nan,        nan, 0.85365854, 0.90243902, 0.87804878,\n",
       "        0.85365854, 0.87804878, 0.90243902, 0.85365854, 0.87804878,\n",
       "        0.85365854,        nan, 0.85365854,        nan, 0.85365854,\n",
       "        0.87804878, 0.85365854,        nan,        nan, 0.90243902,\n",
       "               nan,        nan, 0.85365854, 0.85365854, 0.85365854,\n",
       "        0.82926829, 0.85365854,        nan, 0.87804878,        nan,\n",
       "        0.87804878, 0.87804878,        nan, 0.82926829, 0.87804878,\n",
       "               nan,        nan,        nan, 0.85365854,        nan,\n",
       "        0.87804878, 0.90243902, 0.85365854, 0.87804878,        nan,\n",
       "        0.90243902, 0.90243902,        nan, 0.87804878, 0.87804878,\n",
       "        0.85365854,        nan, 0.87804878,        nan,        nan,\n",
       "        0.90243902, 0.87804878,        nan, 0.82926829, 0.87804878,\n",
       "        0.87804878,        nan, 0.87804878, 0.87804878, 0.87804878,\n",
       "        0.87804878,        nan,        nan, 0.87804878,        nan,\n",
       "        0.87804878, 0.87804878, 0.90243902,        nan, 0.85365854,\n",
       "               nan, 0.87804878,        nan,        nan, 0.85365854,\n",
       "               nan, 0.87804878, 0.87804878, 0.85365854, 0.90243902,\n",
       "        0.87804878, 0.87804878, 0.82926829, 0.85365854,        nan,\n",
       "        0.7804878 ,        nan,        nan, 0.87804878, 0.85365854,\n",
       "               nan, 0.85365854, 0.85365854,        nan, 0.85365854,\n",
       "               nan,        nan, 0.87804878, 0.85365854, 0.85365854,\n",
       "        0.87804878,        nan, 0.90243902, 0.87804878, 0.85365854,\n",
       "        0.90243902,        nan, 0.87804878, 0.85365854,        nan,\n",
       "        0.87804878, 0.87804878, 0.90243902,        nan,        nan,\n",
       "               nan, 0.87804878,        nan, 0.85365854,        nan,\n",
       "               nan, 0.87804878, 0.87804878, 0.90243902, 0.82926829,\n",
       "               nan,        nan,        nan,        nan, 0.85365854,\n",
       "        0.87804878, 0.87804878, 0.82926829, 0.90243902,        nan,\n",
       "        0.90243902,        nan,        nan,        nan, 0.87804878,\n",
       "        0.85365854, 0.87804878,        nan,        nan, 0.87804878,\n",
       "        0.85365854, 0.90243902, 0.85365854, 0.82926829, 0.82926829,\n",
       "        0.85365854, 0.87804878,        nan, 0.87804878,        nan,\n",
       "        0.90243902, 0.87804878, 0.85365854,        nan, 0.87804878,\n",
       "               nan, 0.87804878, 0.87804878,        nan,        nan,\n",
       "               nan, 0.87804878, 0.85365854,        nan, 0.87804878,\n",
       "        0.90243902, 0.90243902, 0.87804878,        nan,        nan,\n",
       "        0.90243902,        nan, 0.82926829, 0.82926829,        nan,\n",
       "        0.87804878,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.87804878,        nan, 0.87804878, 0.87804878,\n",
       "        0.85365854, 0.87804878, 0.82926829, 0.90243902,        nan]),\n",
       " 'mean_test_score': array([       nan,        nan, 0.85644599, 0.870964  , 0.84703833,\n",
       "        0.83739837, 0.84227642, 0.85667828, 0.85168409, 0.84703833,\n",
       "        0.85168409,        nan, 0.85168409,        nan, 0.84216028,\n",
       "        0.85180023, 0.84216028,        nan,        nan, 0.85667828,\n",
       "               nan,        nan, 0.84692218, 0.85644599, 0.84692218,\n",
       "        0.84204413, 0.83739837,        nan, 0.85656214,        nan,\n",
       "        0.84227642, 0.86608595,        nan, 0.82775842, 0.85656214,\n",
       "               nan,        nan,        nan, 0.84216028,        nan,\n",
       "        0.86608595, 0.85191638, 0.83739837, 0.85180023,        nan,\n",
       "        0.86144019, 0.86620209,        nan, 0.85656214, 0.85656214,\n",
       "        0.84216028,        nan, 0.86608595,        nan,        nan,\n",
       "        0.86144019, 0.84703833,        nan, 0.82775842, 0.85656214,\n",
       "        0.85180023,        nan, 0.86132404, 0.85656214, 0.85656214,\n",
       "        0.86132404,        nan,        nan, 0.86132404,        nan,\n",
       "        0.85180023, 0.85656214, 0.84715447,        nan, 0.85168409,\n",
       "               nan, 0.84227642,        nan,        nan, 0.83739837,\n",
       "               nan, 0.84227642, 0.86132404, 0.84216028, 0.85667828,\n",
       "        0.84703833, 0.85656214, 0.83728223, 0.84216028,        nan,\n",
       "        0.82276423,        nan,        nan, 0.86608595, 0.84692218,\n",
       "               nan, 0.8659698 , 0.83739837,        nan, 0.84692218,\n",
       "               nan,        nan, 0.84703833, 0.84216028, 0.85644599,\n",
       "        0.85180023,        nan, 0.86620209, 0.83275261, 0.84692218,\n",
       "        0.86144019,        nan, 0.82799071, 0.8612079 ,        nan,\n",
       "        0.86608595, 0.84227642, 0.86144019,        nan,        nan,\n",
       "               nan, 0.86132404,        nan, 0.83263647,        nan,\n",
       "               nan, 0.86608595, 0.86132404, 0.84239257, 0.82299652,\n",
       "               nan,        nan,        nan,        nan, 0.85644599,\n",
       "        0.85180023, 0.87084785, 0.84680604, 0.86620209,        nan,\n",
       "        0.8757259 ,        nan,        nan,        nan, 0.84703833,\n",
       "        0.85168409, 0.84227642,        nan,        nan, 0.85180023,\n",
       "        0.85168409, 0.85667828, 0.85168409, 0.84204413, 0.84680604,\n",
       "        0.84692218, 0.86132404,        nan, 0.85656214,        nan,\n",
       "        0.870964  , 0.86132404, 0.85168409,        nan, 0.85180023,\n",
       "               nan, 0.84703833, 0.85656214,        nan,        nan,\n",
       "               nan, 0.83751452, 0.85644599,        nan, 0.86132404,\n",
       "        0.86144019, 0.86144019, 0.84703833,        nan,        nan,\n",
       "        0.84715447,        nan, 0.85156794, 0.83728223,        nan,\n",
       "        0.85656214,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.85180023,        nan, 0.84703833, 0.87084785,\n",
       "        0.84216028, 0.84227642, 0.83252033, 0.85667828,        nan]),\n",
       " 'std_test_score': array([       nan,        nan, 0.03370058, 0.05099291, 0.04373497,\n",
       "        0.05060068, 0.03162574, 0.04469267, 0.03803358, 0.05310157,\n",
       "        0.04611751,        nan, 0.03803358,        nan, 0.03538182,\n",
       "        0.03767509, 0.01856997,        nan,        nan, 0.04469267,\n",
       "               nan,        nan, 0.03547549, 0.04519689, 0.03212091,\n",
       "        0.04921136, 0.02731978,        nan, 0.03950946,        nan,\n",
       "        0.03502777, 0.0239651 ,        nan, 0.02321893, 0.04488331,\n",
       "               nan,        nan,        nan, 0.01856997,        nan,\n",
       "        0.04132932, 0.03746252, 0.02731978, 0.04582231,        nan,\n",
       "        0.04319496, 0.04867335,        nan, 0.02967701, 0.02967701,\n",
       "        0.04646399,        nan, 0.0186432 ,        nan,        nan,\n",
       "        0.04815931, 0.03819991,        nan, 0.02767447, 0.03950946,\n",
       "        0.02718713,        nan, 0.03469461, 0.03327886, 0.03327886,\n",
       "        0.0273898 ,        nan,        nan, 0.03469461,        nan,\n",
       "        0.03767509, 0.03327886, 0.03800484,        nan, 0.03492557,\n",
       "               nan, 0.0436717 ,        nan,        nan, 0.03463936,\n",
       "               nan, 0.0436717 , 0.01722459, 0.05328391, 0.05389308,\n",
       "        0.04373497, 0.03950946, 0.02795285, 0.02825524,        nan,\n",
       "        0.0397569 ,        nan,        nan, 0.02830342, 0.04653536,\n",
       "               nan, 0.04433204, 0.02279502,        nan, 0.03212091,\n",
       "               nan,        nan, 0.03819991, 0.02825524, 0.03014916,\n",
       "        0.02718713,        nan, 0.03514695, 0.04195356, 0.03853917,\n",
       "        0.03096409,        nan, 0.03063077, 0.03820768,        nan,\n",
       "        0.0186432 , 0.0551453 , 0.03443156,        nan,        nan,\n",
       "               nan, 0.0407091 ,        nan, 0.02959371,        nan,\n",
       "               nan, 0.03542031, 0.03469461, 0.03483081, 0.04401445,\n",
       "               nan,        nan,        nan,        nan, 0.04519689,\n",
       "        0.04582231, 0.03549829, 0.01971508, 0.04376734,        nan,\n",
       "        0.03775663,        nan,        nan,        nan, 0.0509217 ,\n",
       "        0.03151251, 0.02781061,        nan,        nan, 0.03453483,\n",
       "        0.03151251, 0.04207941, 0.03151251, 0.03257628, 0.03901886,\n",
       "        0.03212091, 0.03469461,        nan, 0.03327886,        nan,\n",
       "        0.04381786, 0.03125634, 0.05079704,        nan, 0.03767509,\n",
       "               nan, 0.03819991, 0.03950946,        nan,        nan,\n",
       "               nan, 0.03745424, 0.03370058,        nan, 0.04834773,\n",
       "        0.04574453, 0.03758044, 0.0509217 ,        nan,        nan,\n",
       "        0.05296142,        nan, 0.04137173, 0.01810655,        nan,\n",
       "        0.03950946,        nan,        nan,        nan,        nan,\n",
       "               nan, 0.03453483,        nan, 0.03819991, 0.0321461 ,\n",
       "        0.03845297, 0.02338103, 0.015146  , 0.04469267,        nan]),\n",
       " 'rank_test_score': array([146, 170,  49,   2,  76, 111,  95,  32,  64,  75,  64, 169,  64,\n",
       "        168, 103,  57, 103, 167, 166,  32, 165, 164,  86,  49,  86, 109,\n",
       "        111, 163,  37, 162,  95,   9, 161, 122,  48, 160, 159, 158, 103,\n",
       "        157,   9,  54, 111,  57, 156,  16,   6, 155,  37,  37, 100, 154,\n",
       "          9, 153, 152,  20,  76, 151, 123,  37,  57, 150,  22,  37,  37,\n",
       "         22, 149, 148,  22, 171,  57,  37,  73, 172,  64, 173,  93, 174,\n",
       "        198, 111, 197,  95,  22, 100,  35,  76,  37, 116, 103, 196, 125,\n",
       "        195, 194,   9,  84, 193,  15, 111, 192,  86, 191, 190,  76, 103,\n",
       "         49,  57, 189,   6, 118,  84,  20, 188, 121,  31, 199,   9,  95,\n",
       "         16, 187, 185, 184,  22, 183, 119, 182, 181,   9,  22,  92, 124,\n",
       "        180, 179, 178, 177,  49,  55,   4,  90,   6, 176,   1, 175, 147,\n",
       "        186,  76,  64,  95, 129, 128,  57,  64,  35,  64, 108,  90,  86,\n",
       "         22, 140,  37, 143,   2,  22,  64, 136,  57, 144,  76,  37, 127,\n",
       "        130, 126, 110,  49, 131,  22,  16,  16,  76, 132, 134,  73, 133,\n",
       "         72, 116, 137,  37, 138, 139, 145, 142, 141,  55, 135,  76,   5,\n",
       "        100,  93, 120,  32, 200])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "063e7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame(rando.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3346a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016156</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 38, 'min_samples_split': 1, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053066</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 152, 'min_samples_split': 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.092324</td>\n",
       "      <td>0.009632</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 61, 'min_samples_split': 2, '...</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.856446</td>\n",
       "      <td>0.033701</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.126488</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.014361</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 87, 'min_samples_split': 2, '...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.870964</td>\n",
       "      <td>0.050993</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 67, 'min_samples_split': 2, '...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.847038</td>\n",
       "      <td>0.043735</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.096945</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 64, 'min_samples_split': 2, '...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.842160</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 24, 'min_samples_split': 2, '...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.842276</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.029721</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 18, 'min_samples_split': 2, '...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.832520</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.121349</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 87, 'min_samples_split': 2, '...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.856678</td>\n",
       "      <td>0.044693</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.036798</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 109, 'min_samples_split': 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.016156      0.004009         0.000000        0.000000   \n",
       "1         0.053066      0.003120         0.000000        0.000000   \n",
       "2         0.092324      0.009632         0.009389        0.001969   \n",
       "3         0.126488      0.016044         0.014361        0.003188   \n",
       "4         0.096154      0.002860         0.009768        0.000753   \n",
       "..             ...           ...              ...             ...   \n",
       "195       0.096945      0.002698         0.009177        0.001952   \n",
       "196       0.036302      0.000797         0.004588        0.000489   \n",
       "197       0.029721      0.001920         0.003590        0.000489   \n",
       "198       0.121349      0.006889         0.010359        0.000500   \n",
       "199       0.036798      0.003277         0.000000        0.000000   \n",
       "\n",
       "    param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "0                   38                       1                      2   \n",
       "1                  152                       1                      1   \n",
       "2                   61                       2                      2   \n",
       "3                   87                       2                      2   \n",
       "4                   67                       2                      2   \n",
       "..                 ...                     ...                    ...   \n",
       "195                 64                       2                      2   \n",
       "196                 24                       2                      1   \n",
       "197                 18                       2                      1   \n",
       "198                 87                       2                      1   \n",
       "199                109                       1                      2   \n",
       "\n",
       "    param_max_features param_criterion  \\\n",
       "0                 sqrt         entropy   \n",
       "1                 log2         entropy   \n",
       "2                 log2         entropy   \n",
       "3                 sqrt         entropy   \n",
       "4                 log2         entropy   \n",
       "..                 ...             ...   \n",
       "195               sqrt            gini   \n",
       "196               sqrt         entropy   \n",
       "197               log2            gini   \n",
       "198               log2         entropy   \n",
       "199               sqrt            gini   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'n_estimators': 38, 'min_samples_split': 1, '...                NaN   \n",
       "1    {'n_estimators': 152, 'min_samples_split': 1, ...                NaN   \n",
       "2    {'n_estimators': 61, 'min_samples_split': 2, '...           0.880952   \n",
       "3    {'n_estimators': 87, 'min_samples_split': 2, '...           0.904762   \n",
       "4    {'n_estimators': 67, 'min_samples_split': 2, '...           0.857143   \n",
       "..                                                 ...                ...   \n",
       "195  {'n_estimators': 64, 'min_samples_split': 2, '...           0.833333   \n",
       "196  {'n_estimators': 24, 'min_samples_split': 2, '...           0.857143   \n",
       "197  {'n_estimators': 18, 'min_samples_split': 2, '...           0.809524   \n",
       "198  {'n_estimators': 87, 'min_samples_split': 2, '...           0.857143   \n",
       "199  {'n_estimators': 109, 'min_samples_split': 1, ...                NaN   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                  NaN                NaN                NaN   \n",
       "1                  NaN                NaN                NaN   \n",
       "2             0.809524           0.904762           0.833333   \n",
       "3             0.809524           0.928571           0.809524   \n",
       "4             0.785714           0.904762           0.809524   \n",
       "..                 ...                ...                ...   \n",
       "195           0.785714           0.904762           0.833333   \n",
       "196           0.809524           0.833333           0.833333   \n",
       "197           0.833333           0.857143           0.833333   \n",
       "198           0.833333           0.904762           0.785714   \n",
       "199                NaN                NaN                NaN   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                  NaN              NaN             NaN              146  \n",
       "1                  NaN              NaN             NaN              170  \n",
       "2             0.853659         0.856446        0.033701               49  \n",
       "3             0.902439         0.870964        0.050993                2  \n",
       "4             0.878049         0.847038        0.043735               76  \n",
       "..                 ...              ...             ...              ...  \n",
       "195           0.853659         0.842160        0.038453              100  \n",
       "196           0.878049         0.842276        0.023381               93  \n",
       "197           0.829268         0.832520        0.015146              120  \n",
       "198           0.902439         0.856678        0.044693               32  \n",
       "199                NaN              NaN             NaN              200  \n",
       "\n",
       "[200 rows x 18 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ceca67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('CV Result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61e0eaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8757259001161442"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rando.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07bb714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran=rando.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52869df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=&#x27;log2&#x27;,\n",
       "                       n_estimators=85)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=&#x27;log2&#x27;,\n",
       "                       n_estimators=85)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features='log2',\n",
       "                       n_estimators=85)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8bb8dc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=&#x27;log2&#x27;,\n",
       "                       n_estimators=85)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=&#x27;log2&#x27;,\n",
       "                       n_estimators=85)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features='log2',\n",
       "                       n_estimators=85)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d32e83e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444444444444444"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b304ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
